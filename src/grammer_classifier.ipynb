{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f700c62c5441473582504ecd2ce25836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a738de90cff6437b88aea4096010e803",
              "IPY_MODEL_152811d892174337a55e3f68d7c3b9c2",
              "IPY_MODEL_87f16981f265408fa7d8377050a3a1b5"
            ],
            "layout": "IPY_MODEL_1c6dda06e9544608a91765139b279895"
          }
        },
        "a738de90cff6437b88aea4096010e803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fba28a48d7a4a1ba5e737711616c9e9",
            "placeholder": "​",
            "style": "IPY_MODEL_4c7652001a5e4a768a17ca272025c4f6",
            "value": ""
          }
        },
        "152811d892174337a55e3f68d7c3b9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23381f3625f94cf49d69f960f4abf87e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b68837786324ea7a960f689c1715988",
            "value": 0
          }
        },
        "87f16981f265408fa7d8377050a3a1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2ebca64f06248be8bba5ca68101d2e0",
            "placeholder": "​",
            "style": "IPY_MODEL_21ff18971c3e4b27937e7d6fb7be16e6",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "1c6dda06e9544608a91765139b279895": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fba28a48d7a4a1ba5e737711616c9e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c7652001a5e4a768a17ca272025c4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23381f3625f94cf49d69f960f4abf87e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5b68837786324ea7a960f689c1715988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2ebca64f06248be8bba5ca68101d2e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21ff18971c3e4b27937e7d6fb7be16e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0C-WuLoCaCo",
        "outputId": "7fb21617-bef8-4760-d48d-613e982afc5b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKFcVe8qPJuP",
        "outputId": "27ada7c7-3c33-4f3f-c349-1580c17bef33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4TOTLiaCPFw",
        "outputId": "266efa38-abbb-422c-e3c8-699998b0f8d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import re\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#loading dataset\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/NLP Assignment/train_data.csv\")\n",
        "df_val=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/NLP Assignment/val_data.csv\")\n",
        "\n",
        "print(df_train.head())\n",
        "print(df_val.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQIrmJQwCZ9k",
        "outputId": "2aa4ebc6-a942-4aea-ca32-d3de4be2026c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               input  labels\n",
            "0    I am reading score of Mahler is Symphony No . .       0\n",
            "1  I am not interested in cars or electric applia...       1\n",
            "2         This is my homework for my English class .       0\n",
            "3  In comparison , Canada is catches increased an...       0\n",
            "4  Fortunately , my older sister is friend is a d...       1\n",
            "                                               input  labels\n",
            "0                            It was the same thing .       0\n",
            "1                          I can study idioms a lot        1\n",
            "2      I just bet some coins for numbers or colors .       0\n",
            "3  Yesterday , I was checking some e - mails on b...       1\n",
            "4  I regret that I have not played the piano very...       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for Null Entries\n",
        "print(df_train.info())\n",
        "print(df_val.info())\n",
        "\n",
        "\n",
        "# Number of positive and negative labels\n",
        "print(df_train.labels.value_counts())\n",
        "print(df_val.labels.value_counts())\n",
        "\n",
        "\n",
        "# Get the lists of labels.\n",
        "labels_train = df_train.labels.values\n",
        "labels_val = df_val.labels.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALo72yMUCZ7C",
        "outputId": "49a670b3-6225-46cb-85e8-2cf5a351a904"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19998 entries, 0 to 19997\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   input   19998 non-null  object\n",
            " 1   labels  19998 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 312.6+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   input   10000 non-null  object\n",
            " 1   labels  10000 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 156.4+ KB\n",
            "None\n",
            "0    9999\n",
            "1    9999\n",
            "Name: labels, dtype: int64\n",
            "0    5000\n",
            "1    5000\n",
            "Name: labels, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''THIS FUNCTION REMOVES THE SPACES BETWEEN THE CONTRACTED WORDS AND REMOVING UNNECESSARY SPACES IN THE SENTENCES\n",
        "            ca n't ==> can't \n",
        "            I 'm ===> I'm ...etc\n",
        "'''\n",
        "def remove_spaces(text):\n",
        "    text = re.sub(r\" '(\\w)\",r\"'\\1\",text)\n",
        "    text = re.sub(r\" \\,\",\",\",text)\n",
        "    text = re.sub(r\" \\.+\",\".\",text)\n",
        "    text = re.sub(r\" \\!+\",\"!\",text)\n",
        "    text = re.sub(r\" \\?+\",\"?\",text)\n",
        "    text = re.sub(\" n't\",\"n't\",text)\n",
        "    text = re.sub(\"[\\(\\)\\;\\_\\^\\`\\/]\",\"\",text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "\n",
        "'''THIS FUNCTION DECONTRACTS THE CONTRACTED WORDS'''\n",
        "\n",
        "def decontract(text):\n",
        "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
        "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "'''THIS FUNCTION PREPROCESSES THE TEXT '''\n",
        "def preprocess(text):\n",
        "    text = remove_spaces(text)   # REMOVING UNWANTED SPACES\n",
        "    text = decontract(text)    # DECONTRACTION\n",
        "    text = text.lower() ## CONVERTING TO LOWER CASE\n",
        "    return text ## RETURNING THE PROCESSED TEXT"
      ],
      "metadata": {
        "id": "Hg66HIfLCZ4d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_train=[]\n",
        "for sentence in df_train.input:\n",
        "  sentence = preprocess(sentence)\n",
        "  sentences_train.append(sentence)\n",
        "\n",
        "\n",
        "sentences_val=[]\n",
        "for sentence in df_val.input:\n",
        "  sentence = preprocess(sentence)\n",
        "  sentences_val.append(sentence)"
      ],
      "metadata": {
        "id": "avgp_yMnCZ1s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length=[]\n",
        "for i in range(len(sentences_train)):\n",
        "    l=len(sentences_train[i])\n",
        "    length.append(l)\n",
        "print(max(length))\n",
        "print(sum(length) / len(length))\n",
        "\n",
        "x=set(length)\n",
        "y=[]\n",
        "for i in x:\n",
        "  y.append(length.count(i))\n",
        "\n",
        "x=list(x)\n",
        "# plotting\n",
        "plt.xlabel('Length')\n",
        "plt.ylabel('count')\n",
        "plt.title('PDF')\n",
        "plt.plot(x, y, marker='o')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "M73ZqKXXCZy8",
        "outputId": "fa1944f6-42b3-4f23-a966-a11563cd4ab4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1911\n",
            "52.75247524752475\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f88aaa8fad0>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "id": "hiQZvQ84CZwa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "f700c62c5441473582504ecd2ce25836",
            "a738de90cff6437b88aea4096010e803",
            "152811d892174337a55e3f68d7c3b9c2",
            "87f16981f265408fa7d8377050a3a1b5",
            "1c6dda06e9544608a91765139b279895",
            "2fba28a48d7a4a1ba5e737711616c9e9",
            "4c7652001a5e4a768a17ca272025c4f6",
            "23381f3625f94cf49d69f960f4abf87e",
            "5b68837786324ea7a960f689c1715988",
            "b2ebca64f06248be8bba5ca68101d2e0",
            "21ff18971c3e4b27937e7d6fb7be16e6"
          ]
        },
        "outputId": "463e32be-b48b-4e64-cd78-8beae00af72a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f700c62c5441473582504ecd2ce25836"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process of tokenization\n",
        "print(' Original: ', sentences_train[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences_train[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_train[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yDWZJDuCZtw",
        "outputId": "7956d026-89fa-4928-eedb-bc2ba810a74f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  i am reading score of mahler is symphony no..\n",
            "Tokenized:  ['i', 'am', 'reading', 'score', 'of', 'ma', '##hler', 'is', 'symphony', 'no', '.', '.']\n",
            "Token IDs:  [1045, 2572, 3752, 3556, 1997, 5003, 13620, 2003, 6189, 2053, 1012, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs for training.\n",
        "input_ids_train = []\n",
        "attention_masks_train = []\n",
        "\n",
        "for sentence in sentences_train:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sentence,                      \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = 350,           \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   \n",
        "                        return_tensors = 'pt',    \n",
        "                   )\n",
        "    \n",
        "    # Adding encoding of sentence to the list.    \n",
        "    input_ids_train.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks_train.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Converting into tensors.\n",
        "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
        "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
        "labels_train = torch.tensor(labels_train)\n",
        "\n",
        "# Print sample sentence \n",
        "print('Original: ', sentences_train[0])\n",
        "print('Token IDs:', input_ids_train[0])\n",
        "print('Token attention_masks: ', attention_masks_train[0])\n",
        "\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs for validation.\n",
        "input_ids_val = []\n",
        "attention_masks_val = []\n",
        "\n",
        "for sentence in sentences_val:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sentence,                      \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = 350,           \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   \n",
        "                        return_tensors = 'pt',    \n",
        "                   )\n",
        "    \n",
        "    input_ids_val.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    attention_masks_val.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
        "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
        "labels_val = torch.tensor(labels_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3qS-E2BCZq5",
        "outputId": "afc6ea3f-8c11-4e98-f884-d37f99b24ffc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  i am reading score of mahler is symphony no..\n",
            "Token IDs: tensor([  101,  1045,  2572,  3752,  3556,  1997,  5003, 13620,  2003,  6189,\n",
            "         2053,  1012,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
            "Token attention_masks:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Combine the training and validation inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "val_dataset = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
      ],
      "metadata": {
        "id": "Lc9NeZ7QCZn2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# batch size of 16 or 32 (the authors recommend). \n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "xHgRFsCUDPJl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# To run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i72hNHrTDPGK",
        "outputId": "c9dfead3-1128-452a-c524-e44cf72c6c78"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2am1tCTDPD1",
        "outputId": "0ca243f4-3cb1-44d1-c380-816a833bc105"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AdamW is a class from the huggingface library \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpDNmSpjDPBw",
        "outputId": "bb4831fb-d41b-44ed-d4bb-0845c4857307"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# But for this task model starts to overfit after epoch 1 so we keep it as 1\n",
        "epochs = 1\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "cqUfrMAKDO_W"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "Hhl1StxMDhmK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "bve9EymNDhid"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 123\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "print('Training............................')\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    #Training\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    \n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. \n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a backward pass.\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.(This is to help prevent the \"exploding gradients\" problem.)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "\n",
        "    # measure our performance on our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation model \n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is validation (not training)\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-43voQNCDhgL",
        "outputId": "5cf305d6-46ea-4abb-ce2f-5da9ed49cd55"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training............................\n",
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "  Batch    50  of    625.    Elapsed: 0:01:26.\n",
            "  Batch   100  of    625.    Elapsed: 0:02:56.\n",
            "  Batch   150  of    625.    Elapsed: 0:04:27.\n",
            "  Batch   200  of    625.    Elapsed: 0:05:58.\n",
            "  Batch   250  of    625.    Elapsed: 0:07:29.\n",
            "  Batch   300  of    625.    Elapsed: 0:09:00.\n",
            "  Batch   350  of    625.    Elapsed: 0:10:31.\n",
            "  Batch   400  of    625.    Elapsed: 0:12:02.\n",
            "  Batch   450  of    625.    Elapsed: 0:13:33.\n",
            "  Batch   500  of    625.    Elapsed: 0:15:05.\n",
            "  Batch   550  of    625.    Elapsed: 0:16:36.\n",
            "  Batch   600  of    625.    Elapsed: 0:18:07.\n",
            "\n",
            "  Average training loss: 0.66\n",
            "  Training epcoh took: 0:18:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.64\n",
            "  Validation took: 0:03:49\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:22:41 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "id": "bb_Yxs-VDhbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "d54b0066-6518-4c47-f47a-0efbe6fcf931"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Training Loss  Valid. Loss  \\\n",
              "epoch                                                                   \n",
              "1      tensor(0.6563, device='cuda:0', grad_fn=<DivBa...         0.64   \n",
              "\n",
              "       Valid. Accur. Training Time Validation Time  \n",
              "epoch                                               \n",
              "1               0.61       0:18:52         0:03:49  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4bc955f9-aecc-440f-9406-0c743eaf6f9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tensor(0.6563, device='cuda:0', grad_fn=&lt;DivBa...</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0:18:52</td>\n",
              "      <td>0:03:49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bc955f9-aecc-440f-9406-0c743eaf6f9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4bc955f9-aecc-440f-9406-0c743eaf6f9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4bc955f9-aecc-440f-9406-0c743eaf6f9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "WEact-HgcT9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataloader = DataLoader(\n",
        "        val_dataset, # The validation samples.\n",
        "        sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "        batch_size = 1 # Evaluate with this batch size.\n",
        "    )\n",
        "\n",
        "logits_arr=[]\n",
        "label_ids_arr=[]\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "\n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_labels = batch[2].to(device)\n",
        "\n",
        "  # Tell pytorch not to bother with constructing the compute graph during\n",
        "  # the forward pass, since this is validation (not training)\n",
        "  with torch.no_grad():        \n",
        "\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      # The \"logits\" are the output\n",
        "      # values prior to applying an activation function like the softmax.\n",
        "      outputs = model(b_input_ids, \n",
        "                      token_type_ids=None, \n",
        "                      attention_mask=b_input_mask\n",
        "                      )\n",
        "      \n",
        "  # Accumulate the validation loss.\n",
        "  loss = outputs.loss\n",
        "  logits = outputs.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits_arr.append(logits.detach().cpu().numpy())\n",
        "  label_ids_arr.append(b_labels.to('cpu').numpy())"
      ],
      "metadata": {
        "id": "VFwK-TElbxae"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating lists of prediction and true label\n",
        "pred_labels=[]\n",
        "labels=[]\n",
        "for i in range(len(logits_arr)):\n",
        "  pred_labels.append(np.argmax(logits_arr[i], axis=1)[0])\n",
        "  labels.append(label_ids_arr[i][0])"
      ],
      "metadata": {
        "id": "M9GVA5dlesWP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics Evaluation\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "cm = confusion_matrix(labels, pred_labels)\n",
        "print(cm)\n",
        "print(\"accuracy_score: \",accuracy_score(labels, pred_labels))\n",
        "print(\"precision_score: \",precision_score(labels, pred_labels))\n",
        "print(\"recall_score: \",recall_score(labels, pred_labels))\n",
        "print(\"f1_score: \",f1_score(labels, pred_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wI_irz_d0SV",
        "outputId": "e7f00b20-7abf-475a-ccc4-6466697aee58"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1629 3371]\n",
            " [ 544 4456]]\n",
            "accuracy_score:  0.6085\n",
            "precision_score:  0.5693113581193305\n",
            "recall_score:  0.8912\n",
            "f1_score:  0.6947844390738287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis of tokens\n",
        "sentence = \"There are many laptopps around!\"\n",
        "print(' Original: ', sentence)\n",
        "print('Tokenized: ', tokenizer.tokenize(sentence))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentence)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b3uAwhKfKHa",
        "outputId": "4f51e2a2-4138-45fe-83cd-96c75d240e39"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  There are many laptopps around!\n",
            "Tokenized:  ['there', 'are', 'many', 'laptop', '##ps', 'around', '!']\n",
            "Token IDs:  [2045, 2024, 2116, 12191, 4523, 2105, 999]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "m58futn3aKuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/NLP Assignment/test_data.csv\")\n",
        "\n",
        "#Checking for Null Entries\n",
        "print(df_test.info())\n",
        "\n",
        "\n",
        "sentences_test=[]\n",
        "for sentence in df_test.input:\n",
        "  sentence = preprocess(sentence)\n",
        "  sentences_test.append(sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a43Fj_0IaKDj",
        "outputId": "2da64bfe-ff82-448d-d0d9-ed2d754afaf3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9972 entries, 0 to 9971\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   input   9972 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 78.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs for training.\n",
        "input_ids_test = []\n",
        "attention_masks_test = []\n",
        "\n",
        "for sentence in sentences_test:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sentence,                      \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = 350,           \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   \n",
        "                        return_tensors = 'pt',    \n",
        "                   )\n",
        "    \n",
        "    # Adding encoding of sentence to the list.    \n",
        "    input_ids_test.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks_test.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Converting into tensors.\n",
        "input_ids_test = torch.cat(input_ids_test, dim=0)\n",
        "attention_masks_test = torch.cat(attention_masks_test, dim=0)\n",
        "\n",
        "# Print sample sentence \n",
        "print('Original: ', sentences_test[0])\n",
        "print('Token IDs:', input_ids_test[0])\n",
        "print('Token attention_masks: ', attention_masks_test[0])"
      ],
      "metadata": {
        "id": "X1gDvXaIpWPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e301d6-c622-4dc5-8faa-731ffba65264"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  i believe they will master japanese soon because they were selected as scholarship recipients.\n",
            "Token IDs: tensor([  101,  1045,  2903,  2027,  2097,  3040,  2887,  2574,  2138,  2027,\n",
            "         2020,  3479,  2004,  6566, 15991,  1012,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
            "Token attention_masks:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the training and validation inputs into a TensorDataset.\n",
        "test_dataset = TensorDataset(input_ids_test, attention_masks_test)\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "        test_dataset, # The validation samples.\n",
        "        sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "        batch_size = 1 # Evaluate with this batch size.\n",
        "    )\n",
        "\n",
        "logits_arr=[]\n",
        "label_ids_arr=[]\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for batch in test_dataloader:\n",
        "\n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "\n",
        "  # Tell pytorch not to bother with constructing the compute graph during\n",
        "  # the forward pass, since this is validation (not training)\n",
        "  with torch.no_grad():        \n",
        "\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      # The \"logits\" are the output\n",
        "      # values prior to applying an activation function like the softmax.\n",
        "      outputs = model(b_input_ids, \n",
        "                      token_type_ids=None, \n",
        "                      attention_mask=b_input_mask\n",
        "                      )\n",
        "      \n",
        "  # Accumulate the validation loss.\n",
        "  loss = outputs.loss\n",
        "  logits = outputs.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits_arr.append(logits.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "NelaPxPVeRHb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating lists of prediction and true label\n",
        "test_labels=[]\n",
        "for i in range(len(logits_arr)):\n",
        "  test_labels.append(np.argmax(logits_arr[i], axis=1)[0])"
      ],
      "metadata": {
        "id": "jYccOB8ifLO3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['labels'] = test_labels\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "muY1j5Xzfjgl",
        "outputId": "33a1495a-6110-4d4c-e20d-980faf378dec"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               input  labels\n",
              "0  I believe they will master Japanese soon becau...       1\n",
              "1                              I am looking for it .       1\n",
              "2  Apple is a round fruit with smooth and colorfu...       1\n",
              "3                              Let It Will Be Push .       0\n",
              "4                  I rode on this ship from Sendai .       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-592c0192-d0db-4955-8023-49bd149635a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I believe they will master Japanese soon becau...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am looking for it .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Apple is a round fruit with smooth and colorfu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Let It Will Be Push .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I rode on this ship from Sendai .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-592c0192-d0db-4955-8023-49bd149635a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-592c0192-d0db-4955-8023-49bd149635a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-592c0192-d0db-4955-8023-49bd149635a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.to_csv(\"shivshankar_shukla_submission.csv\")"
      ],
      "metadata": {
        "id": "tcFsJaaffjaL"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}